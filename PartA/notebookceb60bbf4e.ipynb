{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8000194,"sourceType":"datasetVersion","datasetId":4711023}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pytorch-lightning\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-03T19:41:16.924192Z","iopub.execute_input":"2024-04-03T19:41:16.925167Z","iopub.status.idle":"2024-04-03T19:41:24.043886Z","shell.execute_reply.started":"2024-04-03T19:41:16.925130Z","shell.execute_reply":"2024-04-03T19:41:24.042864Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (2.2.1)\nRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.26.4)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (2.1.2)\nRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.66.1)\nRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (6.0.1)\nRequirement already satisfied: fsspec>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.3.0)\nRequirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.3.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (21.3)\nRequirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.9.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (0.10.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (69.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pytorch-lightning) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.6)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport pytorch_lightning as L\nfrom torchvision import transforms, models,datasets\nimport cv2\nfrom torch.utils.data import Dataset, DataLoader ,random_split,Subset\nimport matplotlib.pyplot as plt \nimport torch.nn as nn \nimport torch.optim as optim \nfrom torchmetrics import MetricCollection, Accuracy\nimport torch.nn.functional as F\nimport torch\nimport os\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:41:24.046069Z","iopub.execute_input":"2024-04-03T19:41:24.046407Z","iopub.status.idle":"2024-04-03T19:41:24.053277Z","shell.execute_reply.started":"2024-04-03T19:41:24.046378Z","shell.execute_reply":"2024-04-03T19:41:24.052347Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"os.environ['PATH_DATASETS'] = '/kaggle/input/neurolist/inaturalist_12K'\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:41:24.054524Z","iopub.execute_input":"2024-04-03T19:41:24.054880Z","iopub.status.idle":"2024-04-03T19:41:24.067559Z","shell.execute_reply.started":"2024-04-03T19:41:24.054850Z","shell.execute_reply":"2024-04-03T19:41:24.066616Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"wandb.login()\n#760091de6b192857b226ee4bdecf4e7f93175087\n\nsweep_config = {\n  'name': 'Assignment2_partA',\n  'method': 'bayes',\n  'metric': {\n      'name': 'Val Accuracy',\n      'goal': 'maximize'   \n    },\n  'parameters': {\n      'epochs': {\n            'values': [5,10,15]\n        },\n        'conv_attributes_channels': {\n            'values': [[32,64,32,64,32],[32,32,32,32,32],[16,32,64,128,256],[32,64,128,256,512],[256,128,64,32,16],[64,64,64,64,64]]\n        },\n        'conv_attributes_kernel_size': {\n            'values': [[3,3,5,7,9],[7,5,5,3,3],[11,7,5,3,3],[3,3,3,5,5],[3,3,3,3,3],[11,7,7,5,3],[11,9,7,5,3],[3,5,7,9,11]]\n        },\n        'pool_attributes_kernel_size': {\n            'values': [[2,2,2,2,2],[2,2,2,1,1],[2,1,3,1,2],[3,3,3,2,2]]\n        },\n        'pool_attributes_stride': {\n            'values': [[2,2,2,2,2],[2,2,2,1,1],[1,1,2,2,2],[1,2,1,2,1],[2,2,2,2,1]]\n        },\n        'dense_layer_size': {\n            'values': [32,64,128,256,512]\n        },\n        'learning_rate': {\n            'values': [0.001,0.0015,0.0001, 0.01]\n        },\n        'activation': {\n            'values': ['relu','elu','gelu','elu']\n        },\n        'dropout': {\n            'values': [0.0 ,0.2 ,0.3 ,0.4 ,0.5]\n        },\n        'batch_normalization': {\n            'values': [True,False]\n        },\n        'batch_size': {\n            'values': [8,16, 32, 64]\n        },\n        'optimizer':{\n              'values': ['adam','nadam','sgd']\n        }\n    }\n}\nsweep_id = wandb.sweep(sweep_config,entity=\"amar_cs23m011\",project=\"Assignment2-CS6910\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class root_dataset(Dataset):\n    def __init__(self):\n        self.dataset1=datasets.ImageFolder(root='/kaggle/input/neurolist/inaturalist_12K/train')\n        l1=int(len(self.dataset1)*0.8)\n        train_dataset,val_dataset=random_split(self.dataset1, [int(len(self.dataset1)*0.8),len(self.dataset1)-l1])\n        #print(len(train_dataset),len(val_dataset))\n        self.train_dataset=train_dataset\n        self.val_dataset=val_dataset\n    def get_train_data(self):\n        return self.train_dataset\n    def get_val_data(self):\n        return self.val_dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:41:24.070022Z","iopub.execute_input":"2024-04-03T19:41:24.070618Z","iopub.status.idle":"2024-04-03T19:41:24.081090Z","shell.execute_reply.started":"2024-04-03T19:41:24.070585Z","shell.execute_reply":"2024-04-03T19:41:24.080274Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class inaturalist_train(Dataset):\n    def __init__(self,train_data):\n        self.target_size=(3,224,224)\n        #dataset1=datasets.ImageFolder(root='/kaggle/input/neurolist/inaturalist_12K/train')\n        self.dataset=train_data    \n        self.transform = transforms.Compose([\n            transforms.Resize(self.target_size[1:]),\n            transforms.ToTensor()\n        ])#self.target_size = target_size \n        \n    def __getitem__(self,idx):\n        image,label=self.dataset[idx]\n        image=self.transform(image)\n        return image,label\n    def __len__(self):\n        return len(self.dataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:41:24.082170Z","iopub.execute_input":"2024-04-03T19:41:24.082464Z","iopub.status.idle":"2024-04-03T19:41:24.101160Z","shell.execute_reply.started":"2024-04-03T19:41:24.082440Z","shell.execute_reply":"2024-04-03T19:41:24.100345Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class inaturalist_val(Dataset):\n    def __init__(self,val_data):\n        self.target_size=(3,224,224)\n        #dataset1=datasets.ImageFolder(root='/kaggle/input/neurolist/inaturalist_12K/train')\n        self.dataset=val_data\n        self.transform = transforms.Compose([\n            transforms.Resize(self.target_size[1:]),\n            transforms.ToTensor()\n        ])#self.target_size = target_size   \n    def __getitem__(self,idx):\n        image,label=self.dataset[idx]\n        image=self.transform(image)\n        return image,label\n    def __len__(self):\n        return len(self.dataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:41:24.102068Z","iopub.execute_input":"2024-04-03T19:41:24.102717Z","iopub.status.idle":"2024-04-03T19:41:24.114757Z","shell.execute_reply.started":"2024-04-03T19:41:24.102694Z","shell.execute_reply":"2024-04-03T19:41:24.113889Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class inaturalist_test(Dataset):\n    def __init__(self):\n        self.target_size=(3,224,224)\n        self.dataset=datasets.ImageFolder(root='/kaggle/input/neurolist/inaturalist_12K/val')\n        self.transform = transforms.Compose([\n            transforms.Resize(self.target_size[1:]),  # Resize images to target size\n            transforms.ToTensor()\n        ])#self.target_size = target_size   \n    def __getitem__(self,idx):\n        image,label=self.dataset[idx]\n        image=self.transform(image)\n        return image,label\n    def __len__(self):\n        return len(self.dataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:41:24.116067Z","iopub.execute_input":"2024-04-03T19:41:24.116474Z","iopub.status.idle":"2024-04-03T19:41:24.128340Z","shell.execute_reply.started":"2024-04-03T19:41:24.116439Z","shell.execute_reply":"2024-04-03T19:41:24.127529Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Activation_Function:\n    def activation_Function(self,activation_function):\n        if activation_function=='relu':\n            return F.relu\n        if activation_function=='gelu':\n            return F.gelu\n        if activation_function=='selu':\n            return F.selu\n        if activation_function=='elu':\n            return F.elu","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:41:24.129376Z","iopub.execute_input":"2024-04-03T19:41:24.129627Z","iopub.status.idle":"2024-04-03T19:41:24.146392Z","shell.execute_reply.started":"2024-04-03T19:41:24.129606Z","shell.execute_reply":"2024-04-03T19:41:24.145532Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"dataset2=inaturalist_test()\nprint(len(dataset2))\ndataloader=DataLoader(dataset=dataset2,batch_size=8,shuffle=False,num_workers=1)\ndatatiter=iter(dataloader)\nfeature,labels=next(datatiter)\nprint(feature.shape,labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:41:24.147454Z","iopub.execute_input":"2024-04-03T19:41:24.147714Z","iopub.status.idle":"2024-04-03T19:41:25.160177Z","shell.execute_reply.started":"2024-04-03T19:41:24.147693Z","shell.execute_reply":"2024-04-03T19:41:25.158668Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"2000\ntorch.Size([8, 3, 224, 224]) tensor([0, 0, 0, 0, 0, 0, 0, 0])\n","output_type":"stream"}]},{"cell_type":"code","source":"class Lightning_CNN(L.LightningModule):\n    def __init__(self,layers,kernel_size,pool_kernel,pool_stride,dense_layer_size,batch_normalization,drop_out,a_fun,optimizer,dense_layer_output,learning_rate):\n        super().__init__()\n        self.batch_normalization=batch_normalization\n        self.drop_out=drop_out\n        self.optimizer=optimizer\n        act_object=Activation_Function()\n        self.dense_layer_output=dense_layer_output\n        self.act_fun=act_object.activation_Function(a_fun)\n        self.learning_rate=learning_rate\n        self.conv1 = nn.Conv2d(3,layers[0], kernel_size=kernel_size[0], padding=1)\n        self.b1=nn.BatchNorm2d(layers[0])\n        self.pool1 = nn.MaxPool2d(kernel_size=pool_kernel[0], stride=pool_stride[0])\n        self.conv2 = nn.Conv2d(layers[0],layers[1],kernel_size=kernel_size[1], padding=1)\n        self.b2=nn.BatchNorm2d(layers[1])\n        self.pool2 = nn.MaxPool2d(kernel_size=pool_kernel[1], stride=pool_stride[1])\n        self.conv3 = nn.Conv2d(layers[1],layers[2], kernel_size=kernel_size[2], padding=1)\n        self.b3=nn.BatchNorm2d(layers[2])\n        self.pool3 = nn.MaxPool2d(kernel_size=pool_kernel[2], stride=pool_stride[2])\n        self.conv4 = nn.Conv2d(layers[2],layers[3], kernel_size=kernel_size[3], padding=1)\n        self.b4=nn.BatchNorm2d(layers[3])\n        self.pool4 = nn.MaxPool2d(kernel_size=pool_kernel[3], stride=pool_stride[3])\n        self.conv5 = nn.Conv2d(layers[3],layers[4], kernel_size=kernel_size[4], padding=1)\n        self.b5=nn.BatchNorm2d(layers[4])\n        self.pool5 = nn.MaxPool2d(kernel_size=pool_kernel[4], stride=pool_stride[4])\n        self.dropout = nn.Dropout(p=drop_out)\n        self.fc1 = nn.Linear(dense_layer_size, self.dense_layer_output)\n        self.fc2 = nn.Linear(self.dense_layer_output, 10)\n    def forward(self,x):\n        if self.batch_normalization==True:\n            x=self.pool1(self.act_fun(self.b1(self.conv1(x))))\n            x=self.pool2(self.act_fun(self.b2(self.conv2(x))))\n            x=self.pool3(self.act_fun(self.b3(self.conv3(x))))\n            x=self.pool4(self.act_fun(self.b4(self.conv4(x))))\n            x=self.pool5(self.act_fun(self.b5(self.conv5(x))))\n        else:\n            x=self.pool1(self.act_fun(self.conv1(x)))\n            x=self.pool2(self.act_fun(self.conv2(x)))\n            x=self.pool3(self.act_fun(self.conv3(x)))\n            x=self.pool4(self.act_fun(self.conv4(x)))\n            x=self.pool5(self.act_fun(self.conv5(x)))\n\n        x=self.dropout(x)\n        x=torch.flatten(x,1)\n        x=self.dropout(x)\n        x=self.act_fun(self.fc1(x))\n        x=self.fc2(x)\n        return x\n    def training_step(self, batch, batch_idx):\n        inputs,labels=batch\n        output=self(inputs)\n        _,preds = torch.max(output, dim=1)\n        loss=F.cross_entropy(output,labels)\n        #train_acc = torch.mean(preds == labels)\n        #print(pred.shape)\n        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        \n        return loss\n    def configure_optimizers(self):\n        if self.optimizer=='adam':\n            optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n            return optimizer\n        if self.optimizer=='nadam':\n            optimizer = torch.optim.NAdam(self.parameters(), lr=self.learning_rate)\n            return optimizer\n        if self.optimizer=='sgd':\n            optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n            return optimizer\n        \n    def validation_step(self,batch,batch_idx):\n        x, y = batch\n        y_pred = self.forward(x)\n        val_loss = F.cross_entropy(y_pred, y)\n        \n        # Compute validation accuracy\n        _, predicted = torch.max(y_pred, 1)\n        val_acc = torch.sum(predicted == y).item() / y.size(0)\n        \n        self.log('val_loss', val_loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_acc', val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        \n        return val_loss\n        \n    \n    def test_step(self, batch, batch_idx):\n        x,y=batch\n        pred=self(x)\n        loss=F.cross_entropy(pred,y)\n        _, predicted = torch.max(pred, 1)\n        accuracy = torch.sum(predicted == y).item() / y.size(0)\n        #print(predicted,accuracy)\n        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log(\"test_accuracy\", accuracy, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        return {\"test_loss\": loss}\n     \n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:41:25.165188Z","iopub.execute_input":"2024-04-03T19:41:25.165574Z","iopub.status.idle":"2024-04-03T19:41:25.199094Z","shell.execute_reply.started":"2024-04-03T19:41:25.165536Z","shell.execute_reply":"2024-04-03T19:41:25.197984Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def main(config=None):\n    with wandb.init(config=config, ):\n        config=wandb.config\n        wandb.run.name = 'bs-'+str(config.batch_size)+'-lr-'+ str(config.learning_rate)+'-ep-'+str(config.epochs)+ '-op-'+str(config.optimizer)+ '-dls-'+str(config.dense_layer_size)+ '-act-'+str(config.activation)+'-do-'+str(config.dropout)+'-bn-'+str(config.batch_normalization)+'-cs-'+str\n        layers=config.conv_attributes_channels\n        kernel_size=config.conv_attributes_kernel_size\n        pool_kernel=config.pool_attributes_kernel_size\n        pool_stride=config.pool_attributes_stride\n        batch_normalization=config.batch_normalization\n        drop_out=config.dropout\n        activation_function=config.activation\n        optimizer=config.optimizer\n        b_size=config.batch_size\n        dense_layer_output=config.dense_layer_size\n        epoch=config.epochs\n        learning_rate=config.learning_rate\n    #aug_bit=True\n        i_d=224\n        D=0\n        for i in range(5):\n            D = (i_d - kernel_size[i])+3\n            D = (D - pool_kernel[i])//pool_stride[i] + 1\n            i_d = D\n        root_obj=root_dataset()\n        train_data=root_obj.get_train_data()\n        val_data=root_obj.get_val_data()\n        dataset1=inaturalist_train(train_data)\n        dataset2=inaturalist_val(val_data)\n        dataset3=inaturalist_test()\n    #print(len(dataset1))\n    #print(len(dataset2))\n        dataloader=DataLoader(dataset=dataset1,batch_size=b_size,shuffle=True,num_workers=2)\n        val_dataloader=DataLoader(dataset=dataset2,batch_size=b_size,shuffle=False,num_workers=2)\n        model=Lightning_CNN(layers,kernel_size,pool_kernel,pool_stride,(D**2)*layers[4],batch_normalization,drop_out,activation_function,optimizer,dense_layer_output,learning_rate) \n        trainer = L.Trainer(accelerator='auto',devices=\"auto\",max_epochs=epoch)\n        trainer.fit(model,dataloader,val_dataloader)\n        test_dataloader=DataLoader(dataset=dataset3,batch_size=8,shuffle=True,num_workers=1)\n        trainer.test(dataloaders=test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:45:10.139325Z","iopub.execute_input":"2024-04-03T19:45:10.139786Z","iopub.status.idle":"2024-04-03T19:45:10.154477Z","shell.execute_reply.started":"2024-04-03T19:45:10.139741Z","shell.execute_reply":"2024-04-03T19:45:10.153514Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"if  __name__ ==\"__main__\":\n    wandb.agent(sweep_id, main, count=60)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:45:13.612886Z","iopub.execute_input":"2024-04-03T19:45:13.613216Z","iopub.status.idle":"2024-04-03T20:04:05.230012Z","shell.execute_reply.started":"2024-04-03T19:45:13.613191Z","shell.execute_reply":"2024-04-03T20:04:05.229055Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64f6273a3b94408d861b4d944ee2b0c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Testing: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bfe659d046c4f56b0e7e9227ed2720e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.398499995470047    \u001b[0m\u001b[35m \u001b[0m│\n│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.7247939109802246    \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.398499995470047     </span>│\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.7247939109802246     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"},"metadata":{}}]}]}