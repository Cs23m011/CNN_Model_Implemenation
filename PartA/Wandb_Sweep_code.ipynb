{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8000194,"sourceType":"datasetVersion","datasetId":4711023}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pytorch-lightning\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-04T12:46:44.597406Z","iopub.execute_input":"2024-04-04T12:46:44.597718Z","iopub.status.idle":"2024-04-04T12:46:57.151034Z","shell.execute_reply.started":"2024-04-04T12:46:44.597689Z","shell.execute_reply":"2024-04-04T12:46:57.150131Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (2.2.1)\nRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.26.4)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (2.1.2)\nRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.66.1)\nRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (6.0.1)\nRequirement already satisfied: fsspec>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.3.0)\nRequirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.3.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (21.3)\nRequirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.9.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (0.10.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (69.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pytorch-lightning) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.6)\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install wandb","metadata":{"execution":{"iopub.status.busy":"2024-04-04T11:15:45.666691Z","iopub.execute_input":"2024-04-04T11:15:45.667384Z","iopub.status.idle":"2024-04-04T11:15:59.423720Z","shell.execute_reply.started":"2024-04-04T11:15:45.667354Z","shell.execute_reply":"2024-04-04T11:15:59.422604Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.4)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.42.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install pytorch-lightning\n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T12:48:14.118674Z","iopub.execute_input":"2024-04-04T12:48:14.119333Z","iopub.status.idle":"2024-04-04T12:48:26.439380Z","shell.execute_reply.started":"2024-04-04T12:48:14.119301Z","shell.execute_reply":"2024-04-04T12:48:26.438196Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (2.2.1)\nRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.26.4)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (2.1.2)\nRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.66.1)\nRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (6.0.1)\nRequirement already satisfied: fsspec>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.3.0)\nRequirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.3.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (21.3)\nRequirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.9.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (0.10.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (69.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pytorch-lightning) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.6)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport pytorch_lightning as L\nfrom torchvision import transforms, models,datasets\nimport cv2\nfrom pytorch_lightning.loggers import WandbLogger\nfrom torch.utils.data import Dataset, DataLoader ,random_split,Subset\nimport matplotlib.pyplot as plt \nimport torch.nn as nn \nimport torch.optim as optim \nfrom torchmetrics import MetricCollection, Accuracy\nimport torch.nn.functional as F\nimport torch\nimport os\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport wandb","metadata":{"execution":{"iopub.status.busy":"2024-04-04T12:48:36.085662Z","iopub.execute_input":"2024-04-04T12:48:36.086037Z","iopub.status.idle":"2024-04-04T12:48:57.992654Z","shell.execute_reply.started":"2024-04-04T12:48:36.086009Z","shell.execute_reply":"2024-04-04T12:48:57.991691Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"os.environ['PATH_DATASETS'] = '/kaggle/input/neurolist/inaturalist_12K'\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:41:24.054524Z","iopub.execute_input":"2024-04-03T19:41:24.054880Z","iopub.status.idle":"2024-04-03T19:41:24.067559Z","shell.execute_reply.started":"2024-04-03T19:41:24.054850Z","shell.execute_reply":"2024-04-03T19:41:24.066616Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"wandb.login()\n#1b3afb4b4413bbbe24d1004eb7aadcd3a31f1b4a\n\nsweep_config = {\n  'name': 'Assignment2_partA',\n  'method': 'bayes',\n  'metric': {\n      'name': 'val_acc',\n      'goal': 'maximize'   \n    },\n  'parameters': {\n      'epochs': {\n            'values': [5,10,15]\n        },\n        'conv_attributes_channels': {\n            'values': [[32,64,32,64,32],[32,32,32,32,32],[16,32,64,128,256],[32,64,128,256,512],[256,128,64,32,16],[64,64,64,64,64]]\n        },\n        'conv_attributes_kernel_size': {\n            'values': [[3,3,5,7,9],[7,5,5,3,3],[11,7,5,3,3],[3,3,3,5,5],[3,3,3,3,3],[11,7,7,5,3],[11,9,7,5,3],[3,5,7,9,11]]\n        },\n        'pool_attributes_kernel_size': {\n            'values': [[2,2,2,2,2],[2,2,2,1,1],[2,1,3,1,2],[3,3,3,2,2]]\n        },\n        'pool_attributes_stride': {\n            'values': [[2,2,2,2,2],[2,2,2,1,1],[1,1,2,2,2],[1,2,1,2,1],[2,2,2,2,1]]\n        },\n        'dense_layer_size': {\n            'values': [32,64,128,256,512]\n        },\n        'learning_rate': {\n            'values': [0.001,0.0015,0.0001, 0.01]\n        },\n        'activation': {\n            'values': ['relu','elu','gelu','elu']\n        },\n        'dropout': {\n            'values': [0.0 ,0.2 ,0.3 ,0.4 ,0.5]\n        },\n        'batch_normalization': {\n            'values': [True,False]\n        },\n        'batch_size': {\n            'values': [8,16, 32, 64]\n        },\n        'optimizer':{\n              'values': ['adam','nadam','sgd']\n        }\n    }\n}\nsweep_id = wandb.sweep(sweep_config,entity=\"amar_cs23m011\",project=\"Assignment2-CS6910\")","metadata":{"execution":{"iopub.status.busy":"2024-04-04T12:49:09.462338Z","iopub.execute_input":"2024-04-04T12:49:09.463237Z","iopub.status.idle":"2024-04-04T12:49:24.037703Z","shell.execute_reply.started":"2024-04-04T12:49:09.463194Z","shell.execute_reply":"2024-04-04T12:49:24.036791Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"Create sweep with ID: kdvn326p\nSweep URL: https://wandb.ai/amar_cs23m011/Assignment2-CS6910/sweeps/kdvn326p\n","output_type":"stream"}]},{"cell_type":"code","source":"class root_dataset(Dataset):\n    def __init__(self):\n        self.dataset1=datasets.ImageFolder(root='/kaggle/input/neurolist/inaturalist_12K/train')\n        l1=int(len(self.dataset1)*0.8)\n        train_dataset,val_dataset=random_split(self.dataset1, [int(len(self.dataset1)*0.8),len(self.dataset1)-l1])\n        #print(len(train_dataset),len(val_dataset))\n        self.train_dataset=train_dataset\n        self.val_dataset=val_dataset\n    def get_train_data(self):\n        return self.train_dataset\n    def get_val_data(self):\n        return self.val_dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-04T12:49:27.686236Z","iopub.execute_input":"2024-04-04T12:49:27.686808Z","iopub.status.idle":"2024-04-04T12:49:27.693285Z","shell.execute_reply.started":"2024-04-04T12:49:27.686777Z","shell.execute_reply":"2024-04-04T12:49:27.692327Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class inaturalist_train(Dataset):\n    def __init__(self,train_data):\n        self.target_size=(3,224,224)\n        #dataset1=datasets.ImageFolder(root='/kaggle/input/neurolist/inaturalist_12K/train')\n        self.dataset=train_data    \n        self.transform = transforms.Compose([\n            transforms.Resize(self.target_size[1:]),\n            transforms.ToTensor()\n        ])#self.target_size = target_size \n        \n    def __getitem__(self,idx):\n        image,label=self.dataset[idx]\n        image=self.transform(image)\n        return image,label\n    def __len__(self):\n        return len(self.dataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T12:49:30.617891Z","iopub.execute_input":"2024-04-04T12:49:30.618369Z","iopub.status.idle":"2024-04-04T12:49:30.625660Z","shell.execute_reply.started":"2024-04-04T12:49:30.618337Z","shell.execute_reply":"2024-04-04T12:49:30.624441Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class inaturalist_val(Dataset):\n    def __init__(self,val_data):\n        self.target_size=(3,224,224)\n        #dataset1=datasets.ImageFolder(root='/kaggle/input/neurolist/inaturalist_12K/train')\n        self.dataset=val_data\n        self.transform = transforms.Compose([\n            transforms.Resize(self.target_size[1:]),\n            transforms.ToTensor()\n        ])#self.target_size = target_size   \n    def __getitem__(self,idx):\n        image,label=self.dataset[idx]\n        image=self.transform(image)\n        return image,label\n    def __len__(self):\n        return len(self.dataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T12:49:34.676554Z","iopub.execute_input":"2024-04-04T12:49:34.677330Z","iopub.status.idle":"2024-04-04T12:49:34.683587Z","shell.execute_reply.started":"2024-04-04T12:49:34.677294Z","shell.execute_reply":"2024-04-04T12:49:34.682677Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class inaturalist_test(Dataset):\n    def __init__(self):\n        self.target_size=(3,224,224)\n        self.dataset=datasets.ImageFolder(root='/kaggle/input/neurolist/inaturalist_12K/val')\n        self.transform = transforms.Compose([\n            transforms.Resize(self.target_size[1:]),  # Resize images to target size\n            transforms.ToTensor()\n        ])#self.target_size = target_size   \n    def __getitem__(self,idx):\n        image,label=self.dataset[idx]\n        image=self.transform(image)\n        return image,label\n    def __len__(self):\n        return len(self.dataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T12:49:38.303325Z","iopub.execute_input":"2024-04-04T12:49:38.303991Z","iopub.status.idle":"2024-04-04T12:49:38.311002Z","shell.execute_reply.started":"2024-04-04T12:49:38.303958Z","shell.execute_reply":"2024-04-04T12:49:38.310002Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Activation_Function:\n    def activation_Function(self,activation_function):\n        if activation_function=='relu':\n            return F.relu\n        if activation_function=='gelu':\n            return F.gelu\n        if activation_function=='selu':\n            return F.selu\n        if activation_function=='elu':\n            return F.elu","metadata":{"execution":{"iopub.status.busy":"2024-04-04T12:49:42.404953Z","iopub.execute_input":"2024-04-04T12:49:42.405363Z","iopub.status.idle":"2024-04-04T12:49:42.411435Z","shell.execute_reply.started":"2024-04-04T12:49:42.405331Z","shell.execute_reply":"2024-04-04T12:49:42.410481Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"dataset2=inaturalist_test()\nprint(len(dataset2))\ndataloader=DataLoader(dataset=dataset2,batch_size=8,shuffle=False,num_workers=1)\ndatatiter=iter(dataloader)\nfeature,labels=next(datatiter)\nprint(feature.shape,labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:41:24.147454Z","iopub.execute_input":"2024-04-03T19:41:24.147714Z","iopub.status.idle":"2024-04-03T19:41:25.160177Z","shell.execute_reply.started":"2024-04-03T19:41:24.147693Z","shell.execute_reply":"2024-04-03T19:41:25.158668Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"2000\ntorch.Size([8, 3, 224, 224]) tensor([0, 0, 0, 0, 0, 0, 0, 0])\n","output_type":"stream"}]},{"cell_type":"code","source":"class Lightning_CNN(L.LightningModule):\n    def __init__(self,layers,kernel_size,pool_kernel,pool_stride,dense_layer_size,batch_normalization,drop_out,a_fun,optimizer,dense_layer_output,learning_rate):\n        super().__init__()\n        self.batch_normalization=batch_normalization\n        self.drop_out=drop_out\n        self.optimizer=optimizer\n        act_object=Activation_Function()\n        self.dense_layer_output=dense_layer_output\n        self.act_fun=act_object.activation_Function(a_fun)\n        self.learning_rate=learning_rate\n        self.conv1 = nn.Conv2d(3,layers[0], kernel_size=kernel_size[0], padding=1)\n        self.b1=nn.BatchNorm2d(layers[0])\n        self.pool1 = nn.MaxPool2d(kernel_size=pool_kernel[0], stride=pool_stride[0])\n        self.conv2 = nn.Conv2d(layers[0],layers[1],kernel_size=kernel_size[1], padding=1)\n        self.b2=nn.BatchNorm2d(layers[1])\n        self.pool2 = nn.MaxPool2d(kernel_size=pool_kernel[1], stride=pool_stride[1])\n        self.conv3 = nn.Conv2d(layers[1],layers[2], kernel_size=kernel_size[2], padding=1)\n        self.b3=nn.BatchNorm2d(layers[2])\n        self.pool3 = nn.MaxPool2d(kernel_size=pool_kernel[2], stride=pool_stride[2])\n        self.conv4 = nn.Conv2d(layers[2],layers[3], kernel_size=kernel_size[3], padding=1)\n        self.b4=nn.BatchNorm2d(layers[3])\n        self.pool4 = nn.MaxPool2d(kernel_size=pool_kernel[3], stride=pool_stride[3])\n        self.conv5 = nn.Conv2d(layers[3],layers[4], kernel_size=kernel_size[4], padding=1)\n        self.b5=nn.BatchNorm2d(layers[4])\n        self.pool5 = nn.MaxPool2d(kernel_size=pool_kernel[4], stride=pool_stride[4])\n        self.dropout = nn.Dropout(p=drop_out)\n        self.fc1 = nn.Linear(dense_layer_size, self.dense_layer_output)\n        self.fc2 = nn.Linear(self.dense_layer_output, 10)\n    def forward(self,x):\n        if self.batch_normalization==True:\n            x=self.pool1(self.act_fun(self.b1(self.conv1(x))))\n            x=self.pool2(self.act_fun(self.b2(self.conv2(x))))\n            x=self.pool3(self.act_fun(self.b3(self.conv3(x))))\n            x=self.pool4(self.act_fun(self.b4(self.conv4(x))))\n            x=self.pool5(self.act_fun(self.b5(self.conv5(x))))\n        else:\n            x=self.pool1(self.act_fun(self.conv1(x)))\n            x=self.pool2(self.act_fun(self.conv2(x)))\n            x=self.pool3(self.act_fun(self.conv3(x)))\n            x=self.pool4(self.act_fun(self.conv4(x)))\n            x=self.pool5(self.act_fun(self.conv5(x)))\n\n        x=self.dropout(x)\n        x=torch.flatten(x,1)\n        x=self.dropout(x)\n        x=self.act_fun(self.fc1(x))\n        x=self.fc2(x)\n        return x\n    def training_step(self, batch, batch_idx):\n        inputs,labels=batch\n        output=self(inputs)\n        _,preds = torch.max(output, dim=1)\n        loss=F.cross_entropy(output,labels)\n        #train_acc = torch.mean(preds == labels)\n        #print(pred.shape)\n        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        \n        return loss\n    def configure_optimizers(self):\n        if self.optimizer=='adam':\n            optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n            return optimizer\n        if self.optimizer=='nadam':\n            optimizer = torch.optim.NAdam(self.parameters(), lr=self.learning_rate)\n            return optimizer\n        if self.optimizer=='sgd':\n            optimizer = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n            return optimizer\n        \n    def validation_step(self,batch,batch_idx):\n        x, y = batch\n        y_pred = self.forward(x)\n        val_loss = F.cross_entropy(y_pred, y)\n        \n        # Compute validation accuracy\n        _, predicted = torch.max(y_pred, 1)\n        val_acc = torch.sum(predicted == y).item() / y.size(0)\n        \n        self.log('val_loss', val_loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_acc', val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        \n        return val_loss\n        \n    \n    def test_step(self, batch, batch_idx):\n        x,y=batch\n        pred=self(x)\n        loss=F.cross_entropy(pred,y)\n        _, predicted = torch.max(pred, 1)\n        accuracy = torch.sum(predicted == y).item() / y.size(0)\n        #print(predicted,accuracy)\n        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        self.log(\"test_accuracy\", accuracy, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n        return {\"test_loss\": loss}\n     \n","metadata":{"execution":{"iopub.status.busy":"2024-04-04T12:49:49.875160Z","iopub.execute_input":"2024-04-04T12:49:49.875998Z","iopub.status.idle":"2024-04-04T12:49:49.905065Z","shell.execute_reply.started":"2024-04-04T12:49:49.875967Z","shell.execute_reply":"2024-04-04T12:49:49.904040Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def main(config=None):\n    with wandb.init(config=config, ):\n        config=wandb.config\n        wandb.run.name = 'bs-'+str(config.batch_size)+'-lr-'+ str(config.learning_rate)+'-ep-'+str(config.epochs)+ '-op-'+str(config.optimizer)+ '-dls-'+str(config.dense_layer_size)+ '-act-'+str(config.activation)+'-do-'+str(config.dropout)+'-bn-'+str(config.batch_normalization)+'-cs-'+','.join(str(x) for x in config.conv_attributes_channels)+'-ck'+','.join(str(x) for x in config.conv_attributes_kernel_size)+'-pk-'+','.join(str(x) for x in config.pool_attributes_kernel_size)+'-ps-'+','.join(str(x) for x in config.pool_attributes_stride)\n        layers=config.conv_attributes_channels\n        kernel_size=config.conv_attributes_kernel_size\n        pool_kernel=config.pool_attributes_kernel_size\n        pool_stride=config.pool_attributes_stride\n        batch_normalization=config.batch_normalization\n        drop_out=config.dropout\n        activation_function=config.activation\n        optimizer=config.optimizer\n        b_size=config.batch_size\n        dense_layer_output=config.dense_layer_size\n        epoch=config.epochs\n        learning_rate=config.learning_rate\n    #aug_bit=True\n        i_d=224\n        D=0\n        for i in range(5):\n            D = (i_d - kernel_size[i])+3\n            D = (D - pool_kernel[i])//pool_stride[i] + 1\n            i_d = D\n        root_obj=root_dataset()\n        train_data=root_obj.get_train_data()\n        val_data=root_obj.get_val_data()\n        dataset1=inaturalist_train(train_data)\n        dataset2=inaturalist_val(val_data)\n        dataset3=inaturalist_test()\n    #print(len(dataset1))\n    #print(len(dataset2))\n        wandb_logger = WandbLogger(project='amar_cs23m011', entity='Assignment2-CS6910')\n        dataloader=DataLoader(dataset=dataset1,batch_size=b_size,shuffle=True,num_workers=2)\n        val_dataloader=DataLoader(dataset=dataset2,batch_size=b_size,shuffle=False,num_workers=2)\n        model=Lightning_CNN(layers,kernel_size,pool_kernel,pool_stride,(D**2)*layers[4],batch_normalization,drop_out,activation_function,optimizer,dense_layer_output,learning_rate) \n        trainer = L.Trainer(accelerator='auto',devices=\"auto\",max_epochs=epoch,logger=wandb_logger)\n        trainer.fit(model,dataloader,val_dataloader)\n        test_dataloader=DataLoader(dataset=dataset3,batch_size=8,shuffle=True,num_workers=1)\n        trainer.test(dataloaders=test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T12:50:00.866970Z","iopub.execute_input":"2024-04-04T12:50:00.867345Z","iopub.status.idle":"2024-04-04T12:50:00.881195Z","shell.execute_reply.started":"2024-04-04T12:50:00.867318Z","shell.execute_reply":"2024-04-04T12:50:00.880138Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"if  __name__ ==\"__main__\":\n    wandb.agent('edmwetvp', main, count=60)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T12:50:07.039322Z","iopub.execute_input":"2024-04-04T12:50:07.040185Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y88yclwq with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: elu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_attributes_channels: [16, 32, 64, 128, 256]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_attributes_kernel_size: [11, 9, 7, 5, 3]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_layer_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n\u001b[34m\u001b[1mwandb\u001b[0m: \tpool_attributes_kernel_size: [2, 1, 3, 1, 2]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tpool_attributes_stride: [1, 2, 1, 2, 1]\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkumarsharmaamar512\u001b[0m (\u001b[33mamar_cs23m011\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240404_125009-y88yclwq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910/runs/y88yclwq' target=\"_blank\">wobbly-sweep-7</a></strong> to <a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910/sweeps/edmwetvp' target=\"_blank\">https://wandb.ai/amar_cs23m011/Assignment2-CS6910/sweeps/edmwetvp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910' target=\"_blank\">https://wandb.ai/amar_cs23m011/Assignment2-CS6910</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910/sweeps/edmwetvp' target=\"_blank\">https://wandb.ai/amar_cs23m011/Assignment2-CS6910/sweeps/edmwetvp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910/runs/y88yclwq' target=\"_blank\">https://wandb.ai/amar_cs23m011/Assignment2-CS6910/runs/y88yclwq</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:391: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eee280037dae4f2c97c503b91ab5a026"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50837cac01fe4b7e9526a57d53abc112"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.27649998664855957   \u001b[0m\u001b[35m \u001b[0m│\n│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2.38393497467041     \u001b[0m\u001b[35m \u001b[0m│\n└───────────────────────────┴───────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.27649998664855957    </span>│\n│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2.38393497467041      </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▆▅▅▄▃▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇███</td></tr><tr><td>val_acc</td><td>▁▄▇▆▂▇█▆▇▅</td></tr><tr><td>val_loss</td><td>▂▂▁▂▅▄▃▄▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>test_accuracy</td><td>0.2765</td></tr><tr><td>test_loss</td><td>2.38393</td></tr><tr><td>train_loss</td><td>1.02141</td></tr><tr><td>trainer/global_step</td><td>1250</td></tr><tr><td>val_acc</td><td>0.2665</td></tr><tr><td>val_loss</td><td>2.44112</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">wobbly-sweep-7</strong> at: <a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910/runs/y88yclwq' target=\"_blank\">https://wandb.ai/amar_cs23m011/Assignment2-CS6910/runs/y88yclwq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240404_125009-y88yclwq/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 17mx45o2 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_attributes_channels: [256, 128, 64, 32, 16]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_attributes_kernel_size: [11, 7, 7, 5, 3]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_layer_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0015\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \tpool_attributes_kernel_size: [2, 1, 3, 1, 2]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tpool_attributes_stride: [1, 2, 1, 2, 1]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240404_130601-17mx45o2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910/runs/17mx45o2' target=\"_blank\">devout-sweep-8</a></strong> to <a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910/sweeps/edmwetvp' target=\"_blank\">https://wandb.ai/amar_cs23m011/Assignment2-CS6910/sweeps/edmwetvp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910' target=\"_blank\">https://wandb.ai/amar_cs23m011/Assignment2-CS6910</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910/sweeps/edmwetvp' target=\"_blank\">https://wandb.ai/amar_cs23m011/Assignment2-CS6910/sweeps/edmwetvp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910/runs/17mx45o2' target=\"_blank\">https://wandb.ai/amar_cs23m011/Assignment2-CS6910/runs/17mx45o2</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:391: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7797fad3d18d4defb4570cacd1306a85"}},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_34/3738648458.py\", line 37, in main\n    trainer.fit(model,dataloader,val_dataloader)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 544, in fit\n    call._call_and_handle_interrupt(\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 987, in _run\n    results = self._run_stage()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1031, in _run_stage\n    self._run_sanity_check()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1060, in _run_sanity_check\n    val_loop.run()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py\", line 182, in _decorator\n    return loop_run(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 135, in run\n    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 396, in _evaluation_step\n    output = call._call_strategy_hook(trainer, hook_name, *step_args)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 309, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 412, in validation_step\n    return self.lightning_module.validation_step(*args, **kwargs)\n  File \"/tmp/ipykernel_34/3704194081.py\", line 72, in validation_step\n    y_pred = self.forward(x)\n  File \"/tmp/ipykernel_34/3704194081.py\", line 31, in forward\n    x=self.pool1(self.act_fun(self.b1(self.conv1(x))))\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/pooling.py\", line 166, in forward\n    return F.max_pool2d(input, self.kernel_size, self.stride,\n  File \"/opt/conda/lib/python3.10/site-packages/torch/_jit_internal.py\", line 488, in fn\n    return if_false(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py\", line 791, in _max_pool2d\n    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.64 GiB. GPU 0 has a total capacty of 14.75 GiB of which 3.20 GiB is free. Process 2134 has 11.55 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 5.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">devout-sweep-8</strong> at: <a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910/runs/17mx45o2' target=\"_blank\">https://wandb.ai/amar_cs23m011/Assignment2-CS6910/runs/17mx45o2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240404_130601-17mx45o2/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 17mx45o2 errored:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_34/3738648458.py\", line 37, in main\n    trainer.fit(model,dataloader,val_dataloader)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 544, in fit\n    call._call_and_handle_interrupt(\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n    return trainer_fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 987, in _run\n    results = self._run_stage()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1031, in _run_stage\n    self._run_sanity_check()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1060, in _run_sanity_check\n    val_loop.run()\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py\", line 182, in _decorator\n    return loop_run(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 135, in run\n    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 396, in _evaluation_step\n    output = call._call_strategy_hook(trainer, hook_name, *step_args)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 309, in _call_strategy_hook\n    output = fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 412, in validation_step\n    return self.lightning_module.validation_step(*args, **kwargs)\n  File \"/tmp/ipykernel_34/3704194081.py\", line 72, in validation_step\n    y_pred = self.forward(x)\n  File \"/tmp/ipykernel_34/3704194081.py\", line 31, in forward\n    x=self.pool1(self.act_fun(self.b1(self.conv1(x))))\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/pooling.py\", line 166, in forward\n    return F.max_pool2d(input, self.kernel_size, self.stride,\n  File \"/opt/conda/lib/python3.10/site-packages/torch/_jit_internal.py\", line 488, in fn\n    return if_false(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py\", line 791, in _max_pool2d\n    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.64 GiB. GPU 0 has a total capacty of 14.75 GiB of which 3.20 GiB is free. Process 2134 has 11.55 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 5.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 17mx45o2 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/3738648458.py\", line 37, in main\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     trainer.fit(model,dataloader,val_dataloader)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 544, in fit\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     call._call_and_handle_interrupt(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return trainer_fn(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 987, in _run\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = self._run_stage()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1031, in _run_stage\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._run_sanity_check()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1060, in _run_sanity_check\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     val_loop.run()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py\", line 182, in _decorator\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return loop_run(self, *args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 135, in run\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\", line 396, in _evaluation_step\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = call._call_strategy_hook(trainer, hook_name, *step_args)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 309, in _call_strategy_hook\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = fn(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 412, in validation_step\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self.lightning_module.validation_step(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/3704194081.py\", line 72, in validation_step\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     y_pred = self.forward(x)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/3704194081.py\", line 31, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     x=self.pool1(self.act_fun(self.b1(self.conv1(x))))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/pooling.py\", line 166, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/_jit_internal.py\", line 488, in fn\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return if_false(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py\", line 791, in _max_pool2d\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.64 GiB. GPU 0 has a total capacty of 14.75 GiB of which 3.20 GiB is free. Process 2134 has 11.55 GiB memory in use. Of the allocated memory 5.73 GiB is allocated by PyTorch, and 5.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: outdfn6f with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_attributes_channels: [64, 64, 64, 64, 64]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_attributes_kernel_size: [3, 5, 7, 9, 11]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_layer_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0015\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \tpool_attributes_kernel_size: [2, 1, 3, 1, 2]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tpool_attributes_stride: [1, 1, 2, 2, 2]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240404_130707-outdfn6f</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910/runs/outdfn6f' target=\"_blank\">true-sweep-9</a></strong> to <a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910/sweeps/edmwetvp' target=\"_blank\">https://wandb.ai/amar_cs23m011/Assignment2-CS6910/sweeps/edmwetvp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910' target=\"_blank\">https://wandb.ai/amar_cs23m011/Assignment2-CS6910</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910/sweeps/edmwetvp' target=\"_blank\">https://wandb.ai/amar_cs23m011/Assignment2-CS6910/sweeps/edmwetvp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/amar_cs23m011/Assignment2-CS6910/runs/outdfn6f' target=\"_blank\">https://wandb.ai/amar_cs23m011/Assignment2-CS6910/runs/outdfn6f</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd71b69ce31a422e9fc1d1844289737f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b9b7c1d2547490aa495c72ef3b00fbc"}},"metadata":{}}]}]}